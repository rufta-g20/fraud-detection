{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9649dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 151112 rows. Missing values handled.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "\n",
    "# Create directory if it doesn't exist \n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Load the merged data from EDA [cite: 123]\n",
    "df = pd.read_csv('../data/processed/fraud_data_with_geo.csv')\n",
    "\n",
    "# 1. Data Cleaning \n",
    "df.drop_duplicates(inplace=True)\n",
    "# Fill missing country values with 'Unknown' to maintain data integrity [cite: 114]\n",
    "df['country'] = df['country'].fillna('Unknown')\n",
    "df = df.fillna(0) \n",
    "\n",
    "print(f\"Data loaded: {df.shape[0]} rows. Missing values handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc6c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete: Time-based and Velocity features added.\n"
     ]
    }
   ],
   "source": [
    "# Correct data types for timestamps [cite: 116]\n",
    "df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
    "df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "\n",
    "# 1. Time-based features [cite: 127-130]\n",
    "df['hour_of_day'] = df['purchase_time'].dt.hour\n",
    "df['day_of_week'] = df['purchase_time'].dt.dayofweek\n",
    "df['time_since_signup'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds()\n",
    "\n",
    "# 2. Transaction frequency/velocity [cite: 126]\n",
    "# Frequency per device and per IP address\n",
    "df['device_freq'] = df.groupby('device_id')['device_id'].transform('count')\n",
    "df['ip_freq'] = df.groupby('ip_address')['ip_address'].transform('count')\n",
    "\n",
    "print(\"Feature engineering complete: Time-based and Velocity features added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e09611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation complete: Categorical columns encoded and numeric features scaled.\n"
     ]
    }
   ],
   "source": [
    "# 3. Categorical Encoding (One-Hot Encoding) [cite: 133]\n",
    "# Including 'country' is vital for geolocation analysis [cite: 124]\n",
    "df_final = pd.get_dummies(df, columns=['source', 'browser', 'sex', 'country'], drop_first=True)\n",
    "\n",
    "# 4. Scaling Numerical Features \n",
    "scaler = StandardScaler()\n",
    "cols_to_scale = ['purchase_value', 'age', 'time_since_signup', 'device_freq', 'ip_freq']\n",
    "df_final[cols_to_scale] = scaler.fit_transform(df_final[cols_to_scale])\n",
    "\n",
    "print(\"Data transformation complete: Categorical columns encoded and numeric features scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7a67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Class Distribution Documentation ---\n",
      "Before SMOTE (Train): {0: 109568, 1: 11321}\n",
      "After SMOTE (Train): {0: 109568, 1: 109568}\n",
      "Test Set (Original Ratio): {0: 27393, 1: 2830}\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y) [cite: 143, 145]\n",
    "X = df_final.drop(['class', 'user_id', 'device_id', 'signup_time', 'purchase_time', 'ip_address'], axis=1)\n",
    "y = df_final['class']\n",
    "\n",
    "# 1. Stratified Train-Test Split [cite: 142]\n",
    "# We split first so that the test set remains \"unseen\" and realistic\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 2. Handle Class Imbalance with SMOTE (On Training Data Only) \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Document the class distribution [cite: 137]\n",
    "print(\"--- Class Distribution Documentation ---\")\n",
    "print(f\"Before SMOTE (Train): {y_train.value_counts().to_dict()}\")\n",
    "print(f\"After SMOTE (Train): {pd.Series(y_train_resampled).value_counts().to_dict()}\")\n",
    "print(f\"Test Set (Original Ratio): {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97263d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 Complete! Training and Test sets are ready for Task 2.\n"
     ]
    }
   ],
   "source": [
    "# Save the engineered features and target for Task 2 [cite: 138-158]\n",
    "X_train_resampled.to_csv('../data/processed/X_train_final.csv', index=False)\n",
    "y_train_resampled.to_csv('../data/processed/y_train_final.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test_final.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test_final.csv', index=False)\n",
    "\n",
    "print(\"Task 1 Complete! Training and Test sets are ready for Task 2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
